# statistical_analysis.py

import pandas as pd
import numpy as np
import networkx as nx
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import logging
from datetime import datetime

class StatisticalAnalyzer:
    """Statistical analysis for pain-related network data"""
    
    def __init__(self):
        self.setup_logging()
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def setup_logging(self):
        """Configure logging"""
        logging.basicConfig(
            filename=f'statistical_analysis_{self.timestamp}.log',
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )

    def calculate_centrality_measures(self, G):
        """Calculate various centrality measures for the network"""
        try:
            centrality_metrics = {
                'degree': nx.degree_centrality(G),
                'betweenness': nx.betweenness_centrality(G),
                'eigenvector': nx.eigenvector_centrality(G)
            }
            
            # Convert to DataFrames
            centrality_dfs = {}
            for metric_name, metric_values in centrality_metrics.items():
                df = pd.DataFrame.from_dict(metric_values, orient='index', 
                                          columns=[f'{metric_name}_centrality'])
                centrality_dfs[metric_name] = df
                
            logging.info(f"Calculated centrality measures successfully")
            return centrality_dfs
            
        except Exception as e:
            logging.error(f"Error in centrality calculation: {str(e)}")
            raise

    def bootstrap_analysis(self, G, n_iterations=1000):
        """Perform bootstrap analysis for network metrics"""
        try:
            bootstrap_results = defaultdict(list)
            
            for i in range(n_iterations):
                # Sample nodes with replacement
                sampled_nodes = np.random.choice(
                    list(G.nodes()), 
                    size=len(G.nodes()), 
                    replace=True
                )
                
                # Create subgraph
                subgraph = G.subgraph(sampled_nodes)
                
                # Calculate metrics
                degree_cent = np.mean(list(nx.degree_centrality(subgraph).values()))
                between_cent = np.mean(list(nx.betweenness_centrality(subgraph).values()))
                
                bootstrap_results['degree'].append(degree_cent)
                bootstrap_results['betweenness'].append(between_cent)
            
            # Calculate confidence intervals
            confidence_intervals = {}
            for metric, values in bootstrap_results.items():
                ci_lower = np.percentile(values, 2.5)
                ci_upper = np.percentile(values, 97.5)
                confidence_intervals[metric] = (ci_lower, ci_upper)
            
            logging.info(f"Completed bootstrap analysis with {n_iterations} iterations")
            return confidence_intervals
            
        except Exception as e:
            logging.error(f"Error in bootstrap analysis: {str(e)}")
            raise

    def perform_significance_tests(self, centrality_dfs):
        """Perform statistical significance tests on centrality measures"""
        try:
            results = {}
            
            for metric_name, df in centrality_dfs.items():
                # Shapiro-Wilk test for normality
                shapiro_stat, shapiro_p = stats.shapiro(df.values)
                
                # One-sample t-test against mean
                t_stat, t_p = stats.ttest_1samp(df.values, df.values.mean())
                
                results[metric_name] = {
                    'shapiro_stat': shapiro_stat,
                    'shapiro_p': shapiro_p,
                    't_stat': t_stat,
                    't_p': t_p
                }
            
            logging.info("Completed significance tests")
            return results
            
        except Exception as e:
            logging.error(f"Error in significance testing: {str(e)}")
            raise

    def generate_statistics_report(self, centrality_dfs, bootstrap_results, significance_tests):
        """Generate comprehensive statistical report"""
        try:
            report = pd.DataFrame()
            
            for metric_name, df in centrality_dfs.items():
                descriptive_stats = df.describe()
                ci = bootstrap_results[metric_name]
                sig_tests = significance_tests[metric_name]
                
                metric_report = pd.DataFrame({
                    'Statistic': [
                        'Mean',
                        'Std',
                        'Min',
                        'Max',
                        'CI_Lower',
                        'CI_Upper',
                        'Shapiro_p',
                        'T_test_p'
                    ],
                    'Value': [
                        descriptive_stats.loc['mean'][0],
                        descriptive_stats.loc['std'][0],
                        descriptive_stats.loc['min'][0],
                        descriptive_stats.loc['max'][0],
                        ci[0],
                        ci[1],
                        sig_tests['shapiro_p'],
                        sig_tests['t_p']
                    ]
                })
                
                report[metric_name] = metric_report['Value']
            
            # Save report
            report_path = f'statistical_report_{self.timestamp}.xlsx'
            report.to_excel(report_path)
            logging.info(f"Statistical report generated: {report_path}")
            
            return report
            
        except Exception as e:
            logging.error(f"Error in report generation: {str(e)}")
            raise

    def visualize_distributions(self, centrality_dfs):
        """Create visualization of centrality distributions"""
        try:
            plt.figure(figsize=(15, 5))
            
            for i, (metric_name, df) in enumerate(centrality_dfs.items(), 1):
                plt.subplot(1, 3, i)
                sns.histplot(df.values, kde=True)
                plt.title(f'{metric_name.capitalize()} Centrality Distribution')
                plt.xlabel('Centrality Value')
                plt.ylabel('Frequency')
            
            plt.tight_layout()
            plot_path = f'centrality_distributions_{self.timestamp}.png'
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            logging.info(f"Distribution plots saved: {plot_path}")
            
        except Exception as e:
            logging.error(f"Error in visualization: {str(e)}")
            raise

def main():
    """Main execution function"""
    analyzer = StatisticalAnalyzer()
    
    try:
        # Load network data (assuming G is your NetworkX graph)
        # This should be replaced with your actual data loading code
        G = nx.Graph()  # Your network data here
        
        # Calculate centrality measures
        centrality_dfs = analyzer.calculate_centrality_measures(G)
        
        # Perform bootstrap analysis
        bootstrap_results = analyzer.bootstrap_analysis(G)
        
        # Perform significance tests
        significance_tests = analyzer.perform_significance_tests(centrality_dfs)
        
        # Generate report
        report = analyzer.generate_statistics_report(
            centrality_dfs, 
            bootstrap_results, 
            significance_tests
        )
        
        # Create visualizations
        analyzer.visualize_distributions(centrality_dfs)
        
        logging.info("Statistical analysis completed successfully")
        
    except Exception as e:
        logging.error(f"Analysis failed: {str(e)}")
        raise

if __name__ == "__main__":
    main()
